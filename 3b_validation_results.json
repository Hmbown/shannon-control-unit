{
  "timestamp": "2025-09-04T20:21:37.930128",
  "base_model": "meta-llama/Llama-3.2-3B",
  "device": "cpu",
  "results": [
    {
      "model": "base_model",
      "avg_bpt": 2.798817397659056,
      "avg_perplexity": 8.92157994044686,
      "details": [
        {
          "loss": 0.3116629123687744,
          "bpt": 0.44963453810344245,
          "perplexity": 1.3656942567881596,
          "n_tokens": 85,
          "category": "code"
        },
        {
          "loss": 2.2271294593811035,
          "bpt": 3.213068626466836,
          "perplexity": 9.273208714980658,
          "n_tokens": 68,
          "category": "technical"
        },
        {
          "loss": 2.920732021331787,
          "bpt": 4.2137256029409675,
          "perplexity": 18.55486504662151,
          "n_tokens": 75,
          "category": "narrative"
        },
        {
          "loss": 1.6932387351989746,
          "bpt": 2.4428271263126615,
          "perplexity": 5.437061422327278,
          "n_tokens": 77,
          "category": "scientific"
        },
        {
          "loss": 2.1750454902648926,
          "bpt": 3.137927342513065,
          "perplexity": 8.80258554502805,
          "n_tokens": 72,
          "category": "conversational"
        },
        {
          "loss": 2.312145709991455,
          "bpt": 3.3357211496173638,
          "perplexity": 10.096064656935503,
          "n_tokens": 1096,
          "category": "validation_file"
        }
      ]
    },
    {
      "model": "3b-scu",
      "avg_bpt": 2.794883552494546,
      "avg_perplexity": 8.89717418469113,
      "details": [
        {
          "loss": 0.3111593723297119,
          "bpt": 0.4489080833861979,
          "perplexity": 1.3650067481573371,
          "n_tokens": 85,
          "category": "code"
        },
        {
          "loss": 2.2535030841827393,
          "bpt": 3.2511177241784224,
          "perplexity": 9.521030456577433,
          "n_tokens": 68,
          "category": "technical"
        },
        {
          "loss": 2.9124772548675537,
          "bpt": 4.201816492299321,
          "perplexity": 18.402329408085162,
          "n_tokens": 75,
          "category": "narrative"
        },
        {
          "loss": 1.6807116270065308,
          "bpt": 2.4247543294467433,
          "perplexity": 5.369375604572044,
          "n_tokens": 77,
          "category": "scientific"
        },
        {
          "loss": 2.1449828147888184,
          "bpt": 3.0945560696878784,
          "perplexity": 8.541894441772868,
          "n_tokens": 72,
          "category": "conversational"
        },
        {
          "loss": 2.3207597732543945,
          "bpt": 3.3481486159687104,
          "perplexity": 10.183408448981934,
          "n_tokens": 1096,
          "category": "validation_file"
        }
      ]
    },
    {
      "model": "3b-fixed",
      "avg_bpt": 2.7985530746565677,
      "avg_perplexity": 8.929737730362652,
      "details": [
        {
          "loss": 0.31120163202285767,
          "bpt": 0.4489690512359288,
          "perplexity": 1.3650644341425435,
          "n_tokens": 85,
          "category": "code"
        },
        {
          "loss": 2.266845941543579,
          "bpt": 3.2703673983241948,
          "perplexity": 9.648919513253642,
          "n_tokens": 68,
          "category": "technical"
        },
        {
          "loss": 2.9173026084899902,
          "bpt": 4.208778006040946,
          "perplexity": 18.49134174023161,
          "n_tokens": 75,
          "category": "narrative"
        },
        {
          "loss": 1.6777048110961914,
          "bpt": 2.4204164110440307,
          "perplexity": 5.353255128373143,
          "n_tokens": 77,
          "category": "scientific"
        },
        {
          "loss": 2.148743152618408,
          "bpt": 3.0999810904266947,
          "perplexity": 8.574075318141862,
          "n_tokens": 72,
          "category": "conversational"
        },
        {
          "loss": 2.317056894302368,
          "bpt": 3.3428064908676096,
          "perplexity": 10.145770248033106,
          "n_tokens": 1096,
          "category": "validation_file"
        }
      ]
    }
  ],
  "summary": {
    "best_model": "3b-scu",
    "best_bpt": 2.794883552494546,
    "base_bpt": 2.798817397659056,
    "improvement": 0.003933845164509897
  }
}